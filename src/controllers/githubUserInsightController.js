import AppError from './../utils/CustomError.js';
import scrapeMultiplePages from './../services/githubUserScraper.js';
import GitHubProfileScraper from './../services/GithubUserProfileScraper.js';
import analyzeGithubProfiles from './../services/aiRequestHandler.js' 


// Use the list of github URL generated by page scraper and then use them in class to find the detailed information about each user 
async function scrapeUserProfiles(userData) {
  let profileUrls = [];
  
  for(const key in userData){
    if(userData.hasOwnProperty(key)){
      profileUrls.push(userData[key].profileUrl)
    }
  }

  const scraper = new GitHubProfileScraper();
  
  try {
    await scraper.initialize();
    const results = await scraper.scrapeMultipleProfiles(profileUrls, 'scraped_github_profiles.json');
    return results;

  } catch (error) {
    throw new AppError(500, `Failed to scrape user profiles: ${error.message}`, error )
  
  } finally {
    await scraper.close();
  }
}

async function collectUserInsights( searchTerm ){
  try{
    const usersList = await scrapeMultiplePages(3, searchTerm);
    const detailedProfiles = await scrapeUserProfiles(usersList);
    const aiAnalyzedResults = await analyzeGithubProfiles(detailedProfiles);
  
    return aiAnalyzedResults;

  } catch (error){
    throw error;
  }
}

export default collectUserInsights;
